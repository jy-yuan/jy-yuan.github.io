---
layout: about
title: About
permalink: /
subtitle:

profile:
  align: right
  image: WechatIMG198-min.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>6100 Main St</p>
    <p>Houston, TX 77005</p>
    <p>jy101 [at] rice.edu</p>

news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

### About me

I’m Jiayi Yuan ([dʒa-ˈi:], 袁加熠), a Ph.D. candidate from the Department of [Computer Science at Rice University](https://cs.rice.edu/), advised by Dr. [Xia "Ben" Hu](https://cs.rice.edu/~xh37/index.html). I aim to build **efficient machine learning algorithms and systems (MLSys)** through methods like *quantization*, *sparsity* and *re-parameterization* while enhancing system **robustness** and **security**. My research applications span language, vision, time series, graph, and healthcare domains. Recently, I've been working on:

- Efficiency problems of long-context LLMs. [[KIVI]](https://arxiv.org/pdf/2402.02750) [[KVBench]](https://arxiv.org/pdf/2407.01527) [[Stop Overthinking]](https://arxiv.org/pdf/2503.16419) [[AutoL2S]](https://arxiv.org/pdf/2505.22662)

- LLM post-training: finetune, RL, and evaluation. [[Give Me FP32]](https://arxiv.org/pdf/2506.09501) [[The Science]](https://arxiv.org/pdf/2502.09670) [[DHP]](https://arxiv.org/pdf/2408.13704)

- LLM Agent, LLM Routing, LLM safety. [[Honeypot]](https://arxiv.org/pdf/2310.18633) [[LTSM]](https://arxiv.org/pdf/2406.14045) [[Taylor Unswift]](https://arxiv.org/pdf/2410.05331) [[LoRATK]](https://arxiv.org/pdf/2403.00108)

Previously, I received my bachelor’s degree in computer science from [Tsinghua University](https://www.tsinghua.edu.cn/en/), where I also studied statistics as a minor.

I lived in Beijing for 22 years and in Houston for ``$YEAR-2022`` year~~(~~s~~)~~.

<span style="color:red">I am seeking full-time research scientist/engineer positions. Please feel free to contact me regarding any opportunities!</span>

### Education & Experience

- Internship, 2025, NVIDIA

- Internship, 2024, Amazon

- Ph.D. in Computer Science, 2022 - 2026 (expected). Rice University

- B.Eng. in Computer Science and Technology, 2017 - 2021. Tsinghua University

### Highlights

- ["Give me FP32"](https://arxiv.org/abs/2506.09501) studies nondeterminism, which has become a heated topic; e.g., it was recently featured in a [blog post](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/) by Thinking Machines Lab.

- [KIVI](https://arxiv.org/abs/2402.02750) largely inspires [KV Cache quantization in Huggingface](https://huggingface.co/docs/transformers/v4.49.0/en/kv_cache#quantized-cache) and is integrated into [Transformers](https://github.com/huggingface/transformers/blob/main/src/transformers/cache_utils.py). Full code is available [here](https://github.com/jy-yuan/KIVI).

- [Rice News](https://cs.rice.edu/news/large-language-models-could-be-key-better-patient-trial-matching): Large language models could be the key to better patient-trial matching - Rice CS Ph.D. student wins AMIA Best Student Paper Award.

- [Rice News](https://cs.rice.edu/news/rice-cs-xia-ben-hu-investigates-llms-and-likely-applications): Rice CS' Xia Ben Hu investigates LLMs and likely applications.

### News

- ["Give Me FP32 or Give Me Death"](https://arxiv.org/abs/2506.09501) got accepted to NeurIPS 2025 as an **Oral** (77 out of 21575 submissions) — numerical precision errors have become a hot topic! [Code](https://github.com/nanomaoli/llm_reproducibility) & [Talk](https://youtu.be/xtzACc7qbyI?si=Y-mYxFlXZ9zcmz6-)

- I got three papers at NAACL, ACL, and EMNLP 2025 each, wish I got to visit Albuquerque, Vienna, and Suzhou this year

- One survey on [efficient LLM reasoning](https://arxiv.org/abs/2503.16419) has been accepted by TMLR! Feel free to [UPVOTE](https://huggingface.co/papers/2503.16419)

- Check out our recent insights and discussions on [LLM evaluation](https://arxiv.org/abs/2502.09670)

- Two papers accepted by EMNLP 2024 (Main + Finding). See you in Miami!

- Check out our recent benchmarking works on [KV Cache compression](https://arxiv.org/abs/2407.01527), [time series foundation models](https://arxiv.org/abs/2406.14045) and [LLM evaluation](https://arxiv.org/abs/2408.13704)!

- KIVI and SEED-GNN got accepted by ICML 2024. See you in Vienna!

- Our LLM-PTM paper is selected as a best student paper at AMIA 2023

- One paper accepted by NeurIPS 2023

- Joined [Microsoft Accelerating Foundation Models Research](https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/) program

<!-- - Two papers accepted by AMIA 2023 -->

- ...

### Publications

Please refer to [publications](https://jy-yuan.github.io/publications/) or [Google Scholar](https://scholar.google.com/citations?user=XMrlrV8AAAAJ).
